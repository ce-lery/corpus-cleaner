#include <gtest/gtest.h>
#include "../corpus_cleaner/corpus_cleaner.hpp"
#include "../corpus_cleaner/util.hpp"
#include "../corpus_cleaner/normalizer.hpp"

// namespace {

class CorpusCleanerTest : public ::testing::Test {
protected:
    // You can freely delete empty functions in the following functions.
    uint32_t min_length=5;
    uint32_t max_length = 1000;
    set<string> accept_language{"__label__ja"};
    Document document;
    string sentence="";
    const string output_path = "../data/output/";
    const string intermediate_path = "../data/intermediate/"; 
    CorpusCleanerTest() {
        // Write the setup that will be executed for each test here.
    }

    virtual ~CorpusCleanerTest() {
        // Write here the clean-up that will be executed 
        //after each test and will not throw an exception.
    }

    // When constructor and destructor are not enough.
    // You can define the following methods:

    virtual void SetUp() {
        // This code is right after the constructor (just before each test)
        // will be called.
        mkdir(output_path.c_str(), 0777);
        mkdir(intermediate_path.c_str(), 0777);
    }

    virtual void TearDown() {
        // This code is placed immediately after each test (just before the destructor)
        // will be called.
        RemoveFolder(output_path);
        RemoveFolder(intermediate_path);
    }

    // Objects declared here are available to all tests within the test case.
    //string a;
    //uin32_t b;
};

// } //namespace

bool CompareFiles(const string& file1, const string& file2) {
    ifstream f1(file1, ios::binary);
    ifstream f2(file2, ios::binary);

    //compare file size
    if(filesystem::file_size(file1)!=filesystem::file_size(file2))  return false;

    // compare file contents
    if (f1 && f2) {
        char c1, c2;
        while (f1.get(c1) && f2.get(c2)) {
            if (c1 != c2)   return false; //file1!=file2
        }
        return true; //file1==file2
    } 
    else    return false; //can't open file, or can't find file.
}

TEST_F(CorpusCleanerTest, LengthFilter) {
    GenerateDedupLSH generate_dedup_lsh(5,200,20,10);
    LSHDeduplicator deduplicator(true,"../data/output/blacklist.txt",true,5120);
    CorpusCleaner corpus_cleaner("../data/input/",
                                 "../data/output/",
                                 min_length,
                                 max_length,
                                 accept_language,
                                 true,
                                 true,
                                 0.3,
                                 15000,
                                 &generate_dedup_lsh,
                                 &deduplicator);

    document.is_rejected=false;
    for(int i=0;i<1001;i++) sentence+="„ÅÇ";
    document.text = sentence;
    corpus_cleaner.LengthFilter(document);
    ASSERT_TRUE(document.text == sentence);
    ASSERT_TRUE(document.is_rejected==true);

    document.is_rejected=false;
    document.text = "„ÅÇ„ÄÇ";
    corpus_cleaner.LengthFilter(document);
    ASSERT_TRUE(document.text == "„ÅÇ„ÄÇ");
    ASSERT_TRUE(document.is_rejected==true);

    document.text = "AAA„ÄÇ";
    document.is_rejected=false;
    corpus_cleaner.LengthFilter(document);
    ASSERT_TRUE(document.text == "AAA„ÄÇ");
    ASSERT_TRUE(document.is_rejected==true);

    document.text = "„Åì„Çì„Å´„Å°„ÅØ„ÄÇ„Åì„Çì„Å´„Å°„ÅØ„ÄÇ„Åì„Çì„Å´„Å°„ÅØ„ÄÇ";
    document.is_rejected=false;
    corpus_cleaner.LengthFilter(document);
    ASSERT_TRUE(document.text == "„Åì„Çì„Å´„Å°„ÅØ„ÄÇ„Åì„Çì„Å´„Å°„ÅØ„ÄÇ„Åì„Çì„Å´„Å°„ÅØ„ÄÇ");
    ASSERT_TRUE(document.is_rejected==false);

    document.text = "„Åì„Çì„Å∞„Çì„Çè„ÄÇ";
    document.is_rejected=false;
    corpus_cleaner.LengthFilter(document);
    ASSERT_TRUE(document.text == "„Åì„Çì„Å∞„Çì„Çè„ÄÇ");
    ASSERT_TRUE(document.is_rejected==false);
}


TEST_F(CorpusCleanerTest, ZeroPunctuationFilter) {
    GenerateDedupLSH generate_dedup_lsh(5,200,20,10);
    LSHDeduplicator deduplicator(true,"../data/output/blacklist.txt",true,5120);
    CorpusCleaner corpus_cleaner("../data/input/",
                                 "../data/output/",
                                 min_length,
                                 max_length,
                                 accept_language,
                                 true,
                                 true,
                                 0.3,
                                 15000,
                                 &generate_dedup_lsh,
                                 &deduplicator);

    document.is_rejected=false;
    document.text = "Êù±‰∫¨„ÄÄÂ§ßÈò™„ÄÄÂêçÂè§Â±ã„ÄÄÊ®™Êµú";
    corpus_cleaner.ZeroPunctuationFilter(document);
    ASSERT_TRUE(document.is_rejected==true);

    document.is_rejected=false;
    document.text = "„Åì„Çì„Å´„Å°„Çè„ÄÇ";
    corpus_cleaner.ZeroPunctuationFilter(document);
    ASSERT_TRUE(document.is_rejected==false);
    
    document.is_rejected=false;
    document.text = "1972Âπ¥5ÊúàÔºöÂ§ßÈüìËà™Á©∫„Åå„ÇΩ„Ç¶„É´Á∑ö„ÅßÂ∞±Ëà™ ";
    corpus_cleaner.ZeroPunctuationFilter(document);
    ASSERT_TRUE(document.is_rejected==true);    
    
    document.is_rejected=false;
    document.text = "„ÄåÂãù„Å¶„Å∞„Çà„Åã„Çç„ÅÜ„Å™„ÅÆ„Å†„Ç°„Ç°„Ç°„Ç°„ÉÉ!!„Äç";
    corpus_cleaner.ZeroPunctuationFilter(document);
    ASSERT_TRUE(document.is_rejected==false);

    document.is_rejected=false;
    document.text = "„Äå„Åä„Åæ„Åà„ÅØ‚Ä¶‚Ä¶Ëá™ÂàÜ„Åå„ÄéÊÇ™„Äè„Å†„Å®Ê∞ó„Å•„ÅÑ„Å¶„ÅÑ„Å™„ÅÑ‚Ä¶„ÇÇ„Å£„Å®„ÇÇ„Éâ„ÇπÈªí„ÅÑ„ÄéÊÇ™„Äè„Å†„Äç";
    corpus_cleaner.ZeroPunctuationFilter(document);
    ASSERT_TRUE(document.is_rejected==true);    

    document.is_rejected=false;
    document.text = "https://github.com/";
    corpus_cleaner.ZeroPunctuationFilter(document);
    ASSERT_TRUE(document.is_rejected==false);
}

TEST_F(CorpusCleanerTest, URLRemover) {
    GenerateDedupLSH generate_dedup_lsh(5,200,20,10);
    LSHDeduplicator deduplicator(true,"../data/output/blacklist.txt",true,5120);
    CorpusCleaner corpus_cleaner("../data/input/",
                                 "../data/output/",
                                 min_length,
                                 max_length,
                                 accept_language,
                                 true,
                                 true,
                                 0.3,
                                 15000,
                                 &generate_dedup_lsh,
                                 &deduplicator);
    document.is_rejected=false;
    document.text = "https://qiita.com/„Åì„Çå„ÅØqiita„ÅÆURL„Åß„Åô";
    corpus_cleaner.URLRemover(document);
    ASSERT_TRUE(document.text == "„Åì„Çå„ÅØqiita„ÅÆURL„Åß„Åô");
    ASSERT_TRUE(document.is_rejected==false);
    ASSERT_TRUE(document.metadata.find("URLRemover")!=document.metadata.end());

    document.text = "„Åì„Çå„ÅØzenn„ÅÆURL„Åß„Åôhttps://zenn.dev/";
    corpus_cleaner.URLRemover(document);
    ASSERT_TRUE(document.text == "„Åì„Çå„ÅØzenn„ÅÆURL„Åß„Åô");

    document.text = "https://zenn.dev/https://qiita.com/„Åì„Çå„ÅØqiita„Å®zenn„ÅÆURL„Åß„Åô";
    corpus_cleaner.URLRemover(document);
    ASSERT_TRUE(document.text == "„Åì„Çå„ÅØqiita„Å®zenn„ÅÆURL„Åß„Åô");

    document.text = "https://zenn.dev/„ÅÇhttps://qiita.com/„ÅÑhttps://huggingface.co/„ÅÜ";
    corpus_cleaner.URLRemover(document);
    ASSERT_TRUE(document.text == "„ÅÇ„ÅÑ„ÅÜ");

    document.text = "URL„Å´Êó•Êú¨Ë™û„ÅåÂê´„Åæ„Çå„ÇãÂ†¥Âêàhttps://www.google.com/search?q=URL+%E6%97%A5%E6%9C%AC%E8%AA%9E&oq=URL+%E6%97%A5%E6%9C%AC%E8%AA%9E&aqs=chrome..69i57.3480j0j7&sourceid=chrome&ie=UTF-8";
    corpus_cleaner.URLRemover(document);
    ASSERT_TRUE(document.text == "URL„Å´Êó•Êú¨Ë™û„ÅåÂê´„Åæ„Çå„ÇãÂ†¥Âêà");
}

TEST_F(CorpusCleanerTest, MakeStats) {
    string input_path = "../data/input/test_URLRemover.txt";
    double elapsed_time = 11.56;
    string process_name = "URLRemover";
    Stats stats = MakeStats(process_name,input_path,elapsed_time);
    ASSERT_EQ("URLRemover",stats.process_name);
    ASSERT_EQ("",stats.file_name);
    ASSERT_EQ(elapsed_time,stats.elapsed_time);
    ASSERT_EQ(0,stats.result_file_size);
}

TEST_F(CorpusCleanerTest, SpecialCharacterRemover) {
    uint32_t min_length = 10;
    uint32_t max_length = 1000;
    set<string> accept_language{"__label__ja"};
    GenerateDedupLSH generate_dedup_lsh(5,200,20,10);
    LSHDeduplicator deduplicator(true,"../data/output/blacklist.txt",true,5120);
    CorpusCleaner corpus_cleaner("../data/input/",
                                 "../data/output/",
                                 min_length,
                                 max_length,
                                 accept_language,
                                 true,
                                 true,
                                 0.3,
                                 15000,
                                 &generate_dedup_lsh,
                                 &deduplicator);
                                 
    Document document;  
    document.text = "‚òÄ„ÅÇ‚Üê„ÅÑ‚åö„ÅÜ‚§≤„Åà‚≠ê„ÅäüÄÄ";
    cout << document.text << endl;
    document.language = "";
    document.language_score=0;
    corpus_cleaner.SpecialCharacterRemover(document);
    ASSERT_TRUE(document.text == "„ÅÇ„ÅÑ„ÅÜ„Åà„Åä");
    ASSERT_TRUE(document.is_rejected == false);
    ASSERT_TRUE(document.metadata.find("SpecialCharacterRemover") != document.metadata.end());
    ASSERT_TRUE(document.language == "");       
    //ASSERT_TRUE(document.language_score == 0);
    
    document.text = "„Åù„Çç„Åù„ÇçÁã©„Çã„Åã‚Ä¶‚ô†";
    corpus_cleaner.SpecialCharacterRemover(document);
    ASSERT_TRUE(document.text == "„Åù„Çç„Åù„ÇçÁã©„Çã„Åã‚Ä¶");
    
    document.text = "RTX4090ÊúÄÈ´ò‚òÜ‚òÄ‚òÅ‚ô†";
    corpus_cleaner.SpecialCharacterRemover(document);
    ASSERT_TRUE(document.text == "RTX4090ÊúÄÈ´ò");
     
    document.text = "„ÅäËÖπ„ÅåÁ©∫„Åç„Åæ„Åó„Åü‚òπ";
    corpus_cleaner.SpecialCharacterRemover(document);
    ASSERT_TRUE(document.text == "„ÅäËÖπ„ÅåÁ©∫„Åç„Åæ„Åó„Åü");
     
    document.text = "Â¢ÉÁïåÂÄ§„Ç∑„É™„Éº„Ç∫‚òÄ‚üø‚Üê‚áø‚åÄ‚èø‚§Ä‚•ø‚¨Ä‚ØøüÄÄüÉø";
    corpus_cleaner.SpecialCharacterRemover(document);
    ASSERT_TRUE(document.text == "Â¢ÉÁïåÂÄ§„Ç∑„É™„Éº„Ç∫");
}

TEST_F(CorpusCleanerTest, EmojiRemover) {
    GenerateDedupLSH generate_dedup_lsh(5,200,20,10);
    LSHDeduplicator deduplicator(true,"../data/output/blacklist.txt",true,5120);
    CorpusCleaner corpus_cleaner("../data/input/",
                                 "../data/output/",
                                 min_length,
                                 max_length,
                                 accept_language,
                                 true,
                                 true,
                                 0.3,
                                 15000,
                                 &generate_dedup_lsh,
                                 &deduplicator);
    document.text = "„Çà„Çç„Åó„Åè„ÅäÈ°ò„ÅÑ„Åó„Åæ„Åôüòé";
    document.language = "";
    document.language_score=0;
    corpus_cleaner.EmojiRemover(document);
    ASSERT_TRUE(document.text == "„Çà„Çç„Åó„Åè„ÅäÈ°ò„ÅÑ„Åó„Åæ„Åô");
    ASSERT_TRUE(document.is_rejected == false);
    ASSERT_TRUE(document.metadata.find("EmojiRemover") != document.metadata.end());
    ASSERT_TRUE(document.language == "");       
    
    document.text = "„Åì„Çì„Å´„Å°„ÅØüòó„Çà„Çç„Åó„Åè„ÅäÈ°ò„ÅÑ„Åó„Åæ„Åôü§°ü§°";
    corpus_cleaner.EmojiRemover(document);
    ASSERT_TRUE(document.text == "„Åì„Çì„Å´„Å°„ÅØ„Çà„Çç„Åó„Åè„ÅäÈ°ò„ÅÑ„Åó„Åæ„Åô");
    
    
    document.text = "ü§ó„Åäü§ó„ÅØü§ó„Çàü§ó„ÅÜü§ó";
    corpus_cleaner.EmojiRemover(document);
    ASSERT_TRUE(document.text == "„Åä„ÅØ„Çà„ÅÜ");
    
    document.text = "Â¢ÉÁïåÂÄ§ÔºëüåÄ";
    corpus_cleaner.EmojiRemover(document);
    ASSERT_TRUE(document.text == "Â¢ÉÁïåÂÄ§Ôºë");

    document.text = "Â¢ÉÁïåÂÄ§Ôºíüßø";
    corpus_cleaner.EmojiRemover(document);
    ASSERT_TRUE(document.text == "Â¢ÉÁïåÂÄ§Ôºí"); 
}

TEST_F(CorpusCleanerTest, SentenceSegmenter) {
    string input_folder_path = "../data/input/sentence_segment/";
    string output_folder_path = "../data/output/sentence_segment/";
    string intermediate_folder_path = "../data/output/sentence_segment/intermediate/";
    string answer_folder_path = "../data/answer/sentence_segment/";

    RemoveFolder(intermediate_folder_path);
    RemoveFolder(output_folder_path);
    GenerateDedupLSH generate_dedup_lsh(5,200,20,10);
    LSHDeduplicator deduplicator(true,"../data/output/blacklist.txt",true,5120);
    CorpusCleaner corpus_cleaner(input_folder_path,
                                 output_folder_path,
                                 min_length,
                                 max_length,
                                 accept_language,
                                 true,
                                 true,
                                 0.3,
                                 15000,
                                 &generate_dedup_lsh,
                                 &deduplicator);

    // MoveFolder(output_folder_path+"/cleaned/", output_folder_path+"/intermediate/"); 
    // cout << "MoveFolder Completed" << endl;

    corpus_cleaner.SentenceSegmenter( output_folder_path+"/intermediate/",output_folder_path+"/cleaned/");
    cout << "SentenceSegmentation Completed" << endl;
    vector<string> file_list;
    GetFileNameListWithoutExtention(answer_folder_path,&file_list);
    for (int i=0;i<(int)file_list.size();i++){
        ASSERT_TRUE(CompareFiles(output_folder_path+"/cleaned/"+file_list[i]+".jsonl",answer_folder_path+"/"+file_list[i]+".jsonl"));
    }
}


TEST_F(CorpusCleanerTest, Normalizer) {
    //original
    ASSERT_TRUE("Hello,C++!" == NormalizeNeologd("   Hello, C++!   "));// TODO: Write the comment that this normalizer is don't applied for English text. Because spaces are removed.
    ASSERT_TRUE("-" == NormalizeNeologd("Àó÷ä‚Äê‚Äë‚Äí‚Äì‚ÅÉ‚Åª‚Çã‚àí"));
    ASSERT_TRUE("-" == NormalizeNeologd("Ôºç"));
    ASSERT_TRUE("„Éº" == NormalizeNeologd("Ôπ£‚Äî‚Äï‚îÄ‚îÅ„ÉºÔΩ∞"));
    ASSERT_TRUE("Ôºù" == NormalizeNeologd("="));
    ASSERT_TRUE("0123456789" == NormalizeNeologd("ÔºêÔºëÔºíÔºìÔºîÔºïÔºñÔºóÔºòÔºô"));
    ASSERT_TRUE("ABCDEFGHIJKLMNOPQRSTUVWXYZ" == NormalizeNeologd("Ôº°Ôº¢Ôº£Ôº§Ôº•Ôº¶ÔºßÔº®Ôº©Ôº™Ôº´Ôº¨Ôº≠ÔºÆÔºØÔº∞Ôº±Ôº≤Ôº≥Ôº¥ÔºµÔº∂Ôº∑Ôº∏ÔºπÔº∫"));
    ASSERT_TRUE("abcdefghijklmnopqrstuvwxyz" == NormalizeNeologd("ÔΩÅÔΩÇÔΩÉÔΩÑÔΩÖÔΩÜÔΩáÔΩàÔΩâÔΩäÔΩãÔΩåÔΩçÔΩéÔΩèÔΩêÔΩëÔΩíÔΩìÔΩîÔΩïÔΩñÔΩóÔΩòÔΩôÔΩö"));
    ASSERT_TRUE("!\"#$%&\'()*+,-./:;<>?@[¬•]^_`{|}" == NormalizeNeologd("ÔºÅ‚ÄùÔºÉÔºÑÔºÖÔºÜ‚ÄôÔºàÔºâÔºäÔºãÔºåÔºçÔºéÔºèÔºöÔºõÔºúÔºûÔºüÔº†ÔºªÔø•ÔºΩÔºæÔºøÔΩÄÔΩõÔΩúÔΩù"));
    ASSERT_TRUE("Ôºù„ÄÇ„ÄÅ„Éª„Äå„Äç" == NormalizeNeologd("Ôºù„ÄÇ„ÄÅ„Éª„Äå„Äç"));
    ASSERT_TRUE("„Éè„É≥„Ç´„ÇØ" == NormalizeNeologd("ÔæäÔæùÔΩ∂ÔΩ∏"));
    ASSERT_TRUE("o-o" == NormalizeNeologd("o‚Ção"));
    ASSERT_TRUE("majika„Éº" == NormalizeNeologd("majika‚îÅ"));
    ASSERT_TRUE("„Çè„ÅÑ" == NormalizeNeologd("„Çè„Ä∞„ÅÑ"));
    ASSERT_TRUE("„Çπ„Éº„Éë„Éº" == NormalizeNeologd("„Çπ„Éº„Éë„Éº„Éº„Éº„Éº"));
    ASSERT_TRUE("!#" == NormalizeNeologd("!#"));
    ASSERT_TRUE("„Çº„É≥„Ç´„ÇØ„Çπ„Éö„Éº„Çπ" == NormalizeNeologd("„Çº„É≥„Ç´„ÇØ„ÄÄ„Çπ„Éö„Éº„Çπ"));
    ASSERT_TRUE("„Åä„Åä" == NormalizeNeologd("„Åä             „Åä"));
    ASSERT_TRUE("„Åä„Åä" == NormalizeNeologd("      „Åä„Åä"));
    ASSERT_TRUE("„Åä„Åä" == NormalizeNeologd("„Åä„Åä      "));
    ASSERT_TRUE("Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥Ëá™‰ΩúÂÖ•ÈñÄ„ÇíË≤∑„ÅÑ„Åæ„Åó„Åü!!!" ==NormalizeNeologd("Ê§úÁ¥¢ „Ç®„É≥„Ç∏„É≥ Ëá™‰Ωú ÂÖ•ÈñÄ „Çí Ë≤∑„ÅÑ „Åæ„Åó„Åü!!!"));
    ASSERT_TRUE("„Ç¢„É´„Ç¥„É™„Ç∫„É†C" == NormalizeNeologd("„Ç¢„É´„Ç¥„É™„Ç∫„É† C"));
    ASSERT_TRUE("PRMLÂâØË™≠Êú¨" == NormalizeNeologd("„ÄÄ„ÄÄ„ÄÄÔº∞Ôº≤Ôº≠Ôº¨„ÄÄ„ÄÄÂâØ„ÄÄË™≠„ÄÄÊú¨„ÄÄ„ÄÄ„ÄÄ"));
    ASSERT_TRUE("Coding the Matrix" == NormalizeNeologd("Coding the Matrix"));
    ASSERT_TRUE("Âçó„Ç¢„É´„Éó„Çπ„ÅÆÂ§©ÁÑ∂Ê∞¥Sparking Lemon„É¨„É¢„É≥‰∏ÄÁµû„Çä" == NormalizeNeologd("Âçó„Ç¢„É´„Éó„Çπ„ÅÆ„ÄÄÂ§©ÁÑ∂Ê∞¥„ÄÄÔº≥ÔΩêÔΩÅÔΩíÔΩãÔΩâÔΩéÔΩá„ÄÄÔº¨ÔΩÖÔΩçÔΩèÔΩé„ÄÄ„É¨„É¢„É≥‰∏ÄÁµû„Çä"));
    ASSERT_TRUE("Âçó„Ç¢„É´„Éó„Çπ„ÅÆÂ§©ÁÑ∂Ê∞¥-Sparking*Lemon+„É¨„É¢„É≥‰∏ÄÁµû„Çä" == NormalizeNeologd("Âçó„Ç¢„É´„Éó„Çπ„ÅÆ„ÄÄÂ§©ÁÑ∂Ê∞¥-„ÄÄÔº≥ÔΩêÔΩÅÔΩíÔΩãÔΩâÔΩéÔΩá*„ÄÄÔº¨ÔΩÖÔΩçÔΩèÔΩé+„ÄÄ„É¨„É¢„É≥‰∏ÄÁµû„Çä"));
	// cout << "Normalizing Text is completed." << endl;
}

TEST_F(CorpusCleanerTest, NGramTokenize) {
    GenerateDedupLSH generate_dedupe_lsh(3,200,20,10);

    wstring text = L"„Åä„ÅØ„Çà„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô„ÄÇ";
    vector<wstring> ret = generate_dedupe_lsh.NGramTokenize(text, 3);
    for(int i=0;i<(int)ret.size()-3+1;i++)  ASSERT_TRUE(ret[i]==text.substr(i,3));
    ASSERT_TRUE((int)ret.size()==8);

    text = L"„Åä„ÅØ„Çà";
    ret = generate_dedupe_lsh.NGramTokenize(text, 5);
    ASSERT_TRUE(ret[0]==L"„Åä„ÅØ„Çà");
    ASSERT_TRUE((int)ret.size()==1);

    text = L"„Åä„ÅØ„Çà„ÅÜü§ó„Åî„Åñ„ÅÑ„Åæ„Åô„ÄÇHuggingface";
    ret = generate_dedupe_lsh.NGramTokenize(text, 3);
    for(int i=0;i<(int)ret.size()-3+1;i++)  ASSERT_TRUE(ret[i]==text.substr(i,3));
    ASSERT_TRUE((int)ret.size()==20);
}

TEST_F(CorpusCleanerTest, GetMinhash) {
    GenerateDedupLSH generate_dedupe_lsh(3,200,20,10);

    wstring text = L"„Åä„ÅØ„Çà„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô„ÄÇ";
    vector<wstring> tokens = generate_dedupe_lsh.NGramTokenize(text, 3);
    uint64_t minhash = generate_dedupe_lsh.GetMinhash(&tokens,0);

    // cout << minhash<<endl;
    ASSERT_TRUE(minhash==5643264886837621032);
}


TEST_F(CorpusCleanerTest, LSHDeduplicator1) {
    // refer: https://github.com/HojiChar/HojiChar/blob/v0.9.0/tests/filters/test_lsh_deduplication.py

    GenerateDedupLSH generate_dedup_lsh(5,200,20,10);
    vector<string> d1 = generate_dedup_lsh.CalculateLSH(L"ÂêæËº©„ÅØÁå´„Åß„ÅÇ„Çã„ÄÇÂêçÂâç„ÅØ„Åæ„Å†ÁÑ°„ÅÑ„ÄÇ„Å©„Åì„ÅßÁîü„Åæ„Çå„Åü„Åã„Å®„Çì„Å®Ë¶ãÂΩì„Åå„Å§„Åã„Å¨„ÄÇ");
    vector<string> d2 = generate_dedup_lsh.CalculateLSH(L"ÂêæËº©„ÅØÈ≥•„Åß„ÅÇ„Çã„ÄÇÂêçÂâç„ÅØ„Åæ„Å†ÁÑ°„ÅÑ„ÄÇ„Å©„Åì„ÅßÁîü„Åæ„Çå„Åü„Åã„Å®„Çì„Å®Ë¶ãÂΩì„Åå„Å§„Åã„Å¨„ÄÇ");
    vector<string> d3 = generate_dedup_lsh.CalculateLSH(L"Á•áÂúíÁ≤æËàé„ÅÆÈêò„ÅÆÂ£∞„ÄÅË´∏Ë°åÁÑ°Â∏∏„ÅÆÈüø„Åç„ÅÇ„Çä„ÄÇ");

    // cout<<"d1:"<<endl;
    // cout<<"[" <<endl;
    // for(auto lsh:d1) cout << lsh <<endl;
    // cout<<"]" <<endl;

    // cout<<"d2:"<<endl;
    // cout<<"[" <<endl;
    // for(auto lsh:d2) cout << lsh <<endl;
    // cout<<"]" <<endl;

    // cout<<"d3:"<<endl;
    // cout<<"[" <<endl;
    // for(auto lsh:d3) cout << lsh <<endl;
    // cout<<"]" <<endl;

    LSHDeduplicator deduplicator(true,"",true,5120);
    ASSERT_TRUE(deduplicator.Apply(&d1)==false);
    ASSERT_TRUE(deduplicator.Apply(&d2)==true);
    ASSERT_TRUE(deduplicator.Apply(&d3)==false);

}

TEST_F(CorpusCleanerTest, LSHDeduplicator2) {
    // refer: https://github.com/HojiChar/HojiChar/blob/v0.9.0/tests/filters/test_lsh_deduplication.py
    
    GenerateDedupLSH generate_dedup_lsh(5,200,20,10);
    vector<string> d1 = generate_dedup_lsh.CalculateLSH(L"ÂêæËº©„ÅØÁå´„Åß„Åô„ÄÇü§óÂêçÂâç„ÅØ„Åæ„Å†ÁÑ°„ÅÑ„ÄÇ");
    vector<string> d2 = generate_dedup_lsh.CalculateLSH(L"ÂêæËº©„ÅØÁå´„Åß„Åô„ÄÇü§óÂêçÂâç„ÅØ„Åæ„Å†ÁÑ°„ÅÑ„Åß„Åô„ÄÇ");

    // cout<<"d1:"<<endl;
    // cout<<"[" <<endl;
    // for(auto lsh:d1) cout << lsh <<endl;
    // cout<<"]" <<endl;

    // cout<<"d2:"<<endl;
    // cout<<"[" <<endl;
    // for(auto lsh:d2) cout << lsh <<endl;
    // cout<<"]" <<endl;

    LSHDeduplicator deduplicator(true,"",true,5120);
    ASSERT_TRUE(deduplicator.Apply(&d1)==false);
    ASSERT_TRUE(deduplicator.Apply(&d2)==true);

    //cout << deduplicator.Apply(&d1) << endl;
    //false
    //cout << deduplicator.Apply(&d2) << endl;
    //false
}


TEST_F(CorpusCleanerTest, MinhashDeduplication) {
    string input_folder_path = "../data/input/sentence_deduplicate/";
    string output_folder_path = "../data/output/minhash/";
    string intermediate_folder_path = "../data/output/minhash/intermediate/";
    string answer_folder_path = "../data/answer/minhash";

    RemoveFolder(intermediate_folder_path);
    RemoveFolder(output_folder_path);
    mkdir(output_folder_path.c_str(), 0777);

    GenerateDedupLSH generate_dedup_lsh(4,200,20,10);
    LSHDeduplicator deduplicator(true,"../data/output/minhash/blacklist.txt",true,5120);
    CorpusCleaner corpus_cleaner(input_folder_path,
                                 output_folder_path,
                                 min_length,
                                 max_length,
                                 accept_language,
                                 false,
                                 true,
                                 0.3,
                                 15000,
                                 &generate_dedup_lsh,
                                 &deduplicator);

    mkdir(intermediate_folder_path.c_str(), 0777);
    // mkdir(intermediate_folder_path.c_str(), 0777);
    // MoveFolder(output_folder_path+"/cleaned/", output_folder_path+"/intermediate/"); 

    vector<string> filename_list;
    GetFileNameListWithoutExtention(output_folder_path+"/intermediate/",&filename_list);
    // Execute the each CorpusCleaner processing on all files in the intermediate folder.
    for (auto filename: filename_list){
        // load data
        ifstream input_file(output_folder_path+"/intermediate/"+"/"+filename+".txt");
        string  output_file_path(output_folder_path+"/cleaned/"+"/"+filename+".jsonl");
        string line="";
        uint64_t line_count=0;
        while (getline(input_file, line)) {
            Document document;
            ConvertTextToDocument(line,filename,to_string(line_count),document);
            // Loop processing as many times as cleaner_list
            corpus_cleaner.MinhashDeduplication(document);
            // dump data
            WriteDocumentToJsonl(document,output_file_path);
            line_count++;
        }
        input_file.close();   
    }

    vector<string> file_list;
    GetFileNameListWithoutExtention(answer_folder_path,&file_list);
    for (int i=0;i<(int)file_list.size();i++){
        ASSERT_TRUE(CompareFiles(output_folder_path+"/cleaned/"+"/"+file_list[i]+".jsonl",answer_folder_path+"/"+file_list[i]+".jsonl"));
    }
}

TEST_F(CorpusCleanerTest,LanguageFilter) 
{
    GenerateDedupLSH generate_dedup_lsh(5,200,20,10);
    LSHDeduplicator deduplicator(true,"../data/output/blacklist.txt",true,5120);
    CorpusCleaner corpus_cleaner("../data/input/",
                                 "../data/output/",
                                 min_length,
                                 max_length,
                                 accept_language,
                                 true,
                                 true,
                                 0.3,
                                 15000,
                                 &generate_dedup_lsh,
                                 &deduplicator);
    document.text = "ÂêæËº©„ÅØÁå´„Åß„ÅÇ„Çã„ÄÇÂêçÂâç„ÅØ„Åæ„Å†ÁÑ°„ÅÑ„ÄÇ";
    corpus_cleaner.LanguageFilter(document);
    //document.text isn't changed.
    ASSERT_TRUE(document.text == "ÂêæËº©„ÅØÁå´„Åß„ÅÇ„Çã„ÄÇÂêçÂâç„ÅØ„Åæ„Å†ÁÑ°„ÅÑ„ÄÇ"); 
    ASSERT_TRUE(document.is_rejected==false);
    ASSERT_TRUE(document.metadata.find("LanguageFilter")==document.metadata.end());

    document.text = "I am a cat. No name yet.";
    corpus_cleaner.LanguageFilter(document);
    ASSERT_TRUE(document.language=="__label__en");
    ASSERT_TRUE(document.is_rejected==true);
    ASSERT_TRUE(document.metadata.find("LanguageFilter")!=document.metadata.end());
}

TEST_F(CorpusCleanerTest,LanguageFilter2) 
{
    GenerateDedupLSH generate_dedup_lsh(5,200,20,10);
    LSHDeduplicator deduplicator(true,"../data/output/blacklist.txt",true,5120);
    CorpusCleaner corpus_cleaner("../data/input/",
                                 "../data/output/",
                                 min_length,
                                 max_length,
                                 {"__label__en"},
                                 true,
                                 true,
                                 0.3,
                                 15000,
                                 &generate_dedup_lsh,
                                 &deduplicator);
    document.text = "I am a cat. No name yet.";
    corpus_cleaner.LanguageFilter(document);
    ASSERT_TRUE(document.language=="__label__en");
    ASSERT_TRUE(document.is_rejected==false);

    //under.threshold
    document.text = "„Åé„Åégugu";
    corpus_cleaner.LanguageFilter(document);
    ASSERT_TRUE(document.language=="__label__en");
    ASSERT_TRUE(document.language_score<0.3);
    ASSERT_TRUE(document.is_rejected==true);
}

TEST_F(CorpusCleanerTest,QuotesRemover) 
{
    GenerateDedupLSH generate_dedup_lsh(5,200,20,10);
    LSHDeduplicator deduplicator(true,"../data/output/blacklist.txt",true,5120);
    CorpusCleaner corpus_cleaner("../data/input/",
                                 "../data/output/",
                                 min_length,
                                 max_length,
                                 accept_language,
                                 true,
                                 true,
                                 0.3,
                                 15000,
                                 &generate_dedup_lsh,
                                 &deduplicator);
    document.text = "Ëá™Â∑±ÊïôÂ∏´„ÅÇ„ÇäÂ≠¶Áøí„Åæ„Åü„ÅØÂçäÊïôÂ∏´„ÅÇ„ÇäÂ≠¶ÁøíÔºàËã±Ë™ûÁâàÔºâ„Å´„Çà„Å£„Å¶Ë®ìÁ∑¥„ÅåË°å„Çè„Çå„Çã[1]„ÄÇ";
    corpus_cleaner.QuotesRemover(document);
    ASSERT_TRUE(document.text
                =="Ëá™Â∑±ÊïôÂ∏´„ÅÇ„ÇäÂ≠¶Áøí„Åæ„Åü„ÅØÂçäÊïôÂ∏´„ÅÇ„ÇäÂ≠¶ÁøíÔºàËã±Ë™ûÁâàÔºâ„Å´„Çà„Å£„Å¶Ë®ìÁ∑¥„ÅåË°å„Çè„Çå„Çã„ÄÇ");

    document.text = "Ëá™Â∑±ÊïôÂ∏´„ÅÇ„ÇäÂ≠¶Áøí„Åæ„Åü„ÅØÂçäÊïôÂ∏´„ÅÇ„ÇäÂ≠¶ÁøíÔºàËã±Ë™ûÁâàÔºâ„Å´„Çà„Å£„Å¶Ë®ìÁ∑¥„ÅåË°å„Çè„Çå„Çã{2}„ÄÇ";
    corpus_cleaner.QuotesRemover(document);
    ASSERT_TRUE(document.text
                =="Ëá™Â∑±ÊïôÂ∏´„ÅÇ„ÇäÂ≠¶Áøí„Åæ„Åü„ÅØÂçäÊïôÂ∏´„ÅÇ„ÇäÂ≠¶ÁøíÔºàËã±Ë™ûÁâàÔºâ„Å´„Çà„Å£„Å¶Ë®ìÁ∑¥„ÅåË°å„Çè„Çå„Çã„ÄÇ");

    document.text = "„Åì„Çå„ÅØÊñáÁåÆ[123]{456}„ÇíÂèÇÁÖß„Åè„Å†„Åï„ÅÑ„ÄÇ";
    corpus_cleaner.QuotesRemover(document);
    ASSERT_TRUE(document.text
                =="„Åì„Çå„ÅØÊñáÁåÆ„ÇíÂèÇÁÖß„Åè„Å†„Åï„ÅÑ„ÄÇ");

    document.text = "„Åì„Çå„ÅØÊñáÁåÆ[a]„ÇíÂèÇÁÖß„Åè„Å†„Åï„ÅÑ„ÄÇ";
    corpus_cleaner.QuotesRemover(document);
    ASSERT_TRUE(document.text
                =="„Åì„Çå„ÅØÊñáÁåÆ[a]„ÇíÂèÇÁÖß„Åè„Å†„Åï„ÅÑ„ÄÇ");
}

TEST_F(CorpusCleanerTest,KenLMPerplexity) 
{
    vector<wstring> sentence_list;
	sentence_list.push_back(L"Êù±‰∫¨„ÅØ„ÉÉÊô¥„Çå");
	sentence_list.push_back(L"Êù±‰∫¨„ÅØÂÖÉÊ∞ó„Åß„Åô");
	sentence_list.push_back(L"ÂêæËº©„ÅØÁå´„Åß„ÅÇ„Çã.ÂêçÂâç„ÅØ„Åæ„Å†„Å™„ÅÑ.");
	sentence_list.push_back(L"Êù±‰∫¨„ÅØÊô¥„Çå");
	//sentence_list.push_back(L"Êù±‰∫¨ Â§ßÈò™ ÂêçÂè§Â±ã ÁßãÁî∞ ÂçÉËëâ");
	//sentence_list.push_back(L"„ÅÇ„ÅÇ„ÅÇ„ÅÇ„ÅÇ„ÅÇ„ÅÇ");
	//sentence_list.push_back(L"assdofiuslk„ÅÇÔΩìÔΩãÔΩÑÔΩàÔΩäÔΩã");

    vector<double> perplexity_list;
    KenLMFilter kenlm_filter;
    for (wstring sentence:sentence_list) {
        perplexity_list.push_back(kenlm_filter.Perplexity(sentence));
        cout << ConvertWstringToUTF8(sentence) << "perplexity:"<<perplexity_list[(int)perplexity_list.size()-1]<<endl;
	}
    // cout << perplexity_list[6]<<endl;
    //ref: https://google.github.io/googletest/reference/assertions.html
    EXPECT_NEAR(perplexity_list[0],21879.531940405483,0.1);//Êù±‰∫¨„ÅØ„ÉÉÊô¥„Çå
    EXPECT_NEAR(perplexity_list[1],24128.70574300623,0.1);//Êù±‰∫¨„ÅØÂÖÉÊ∞ó„Åß„Åô
    EXPECT_NEAR(perplexity_list[2],4117.138960278464,0.1);//ÂêæËº©„ÅØÁå´„Åß„ÅÇ„Çã„ÄÇÂêçÂâç„ÅØ„Åæ„Å†„Å™„ÅÑ„ÄÇ
    EXPECT_NEAR(perplexity_list[3],17809.198147089162,0.1);//Êù±‰∫¨„ÅØÊô¥„Çå
    //ASSERT_TRUE(perplexity_list[4]>15000);//Êù±‰∫¨ Â§ßÈò™ ÂêçÂè§Â±ã ÁßãÁî∞ ÂçÉËëâ
    //ASSERT_TRUE(perplexity_list[5]>15000);//„ÅÇ„ÅÇ„ÅÇ„ÅÇ„ÅÇ„ÅÇ„ÅÇ
    //ASSERT_TRUE(perplexity_list[6]>15000);//assdofiuslk„ÅÇÔΩìÔΩãÔΩÑÔΩàÔΩäÔΩã

    ASSERT_TRUE(perplexity_list[0]>perplexity_list[3]);//Êù±‰∫¨„ÅØ„ÉÉÊô¥„Çå>Êù±‰∫¨„ÅØÊô¥„Çå
    ASSERT_TRUE(perplexity_list[1]>perplexity_list[3]);//Êù±‰∫¨„ÅØÂÖÉÊ∞ó„Åß„Åô>Êù±‰∫¨„ÅØÊô¥„Çå
}

TEST_F(CorpusCleanerTest,KenLMPerplexityWithSentencePiece) 
{
    vector<wstring> sentence_list;
	sentence_list.push_back(L"Êù±‰∫¨„ÅØ„ÉÉÊô¥„Çå");
	sentence_list.push_back(L"Êù±‰∫¨„ÅØÂÖÉÊ∞ó„Åß„Åô");
	sentence_list.push_back(L"ÂêæËº©„ÅØÁå´„Åß„ÅÇ„Çã. ÂêçÂâç„ÅØ„Åæ„Å†„Å™„ÅÑ.");
	sentence_list.push_back(L"Êù±‰∫¨„ÅØÊô¥„Çå");
	//sentence_list.push_back(L"Êù±‰∫¨ Â§ßÈò™ ÂêçÂè§Â±ã ÁßãÁî∞ ÂçÉËëâ");
	//sentence_list.push_back(L"„ÅÇ„ÅÇ„ÅÇ„ÅÇ„ÅÇ„ÅÇ„ÅÇ");
	//sentence_list.push_back(L"assdofiuslk„ÅÇÔΩìÔΩãÔΩÑÔΩàÔΩäÔΩã");

    vector<double> perplexity_list;
    KenLMFilter kenlm_filter;
    for (wstring sentence:sentence_list) {
        perplexity_list.push_back(kenlm_filter.PerplexityWithSentencePiece(sentence));
        cout << ConvertWstringToUTF8(sentence) << "perplexity:"<<perplexity_list[(int)perplexity_list.size()-1]<<endl;
	}
    // cout << perplexity_list[6]<<endl;
    //ref: https://google.github.io/googletest/reference/assertions.html
    EXPECT_NEAR(perplexity_list[0],10808.575564708846,0.1);//Êù±‰∫¨„ÅØ„ÉÉÊô¥„Çå
    EXPECT_NEAR(perplexity_list[1],14207.90466675276,0.1);//Êù±‰∫¨„ÅØÂÖÉÊ∞ó„Åß„Åô
    EXPECT_NEAR(perplexity_list[2],677.481230499526,0.1);//ÂêæËº©„ÅØÁå´„Åß„ÅÇ„Çã„ÄÇÂêçÂâç„ÅØ„Åæ„Å†„Å™„ÅÑ„ÄÇ
    EXPECT_NEAR(perplexity_list[3],3340.487952615284,0.1);//Êù±‰∫¨„ÅØÊô¥„Çå
    //ASSERT_TRUE(perplexity_list[4]>15000);//Êù±‰∫¨ Â§ßÈò™ ÂêçÂè§Â±ã ÁßãÁî∞ ÂçÉËëâ
    //ASSERT_TRUE(perplexity_list[5]>15000);//„ÅÇ„ÅÇ„ÅÇ„ÅÇ„ÅÇ„ÅÇ„ÅÇ
    //ASSERT_TRUE(perplexity_list[6]>15000);//assdofiuslk„ÅÇÔΩìÔΩãÔΩÑÔΩàÔΩäÔΩã

    ASSERT_TRUE(perplexity_list[0]>perplexity_list[3]);//Êù±‰∫¨„ÅØ„ÉÉÊô¥„Çå>Êù±‰∫¨„ÅØÊô¥„Çå
    ASSERT_TRUE(perplexity_list[1]>perplexity_list[3]);//Êù±‰∫¨„ÅØÂÖÉÊ∞ó„Åß„Åô>Êù±‰∫¨„ÅØÊô¥„Çå
}

TEST_F(CorpusCleanerTest,PerplexityFilter) 
{

    GenerateDedupLSH generate_dedup_lsh(5,200,20,10);
    LSHDeduplicator deduplicator(true,"../data/output/blacklist.txt",true,5120);
    CorpusCleaner corpus_cleaner("../data/input/",
                                 "../data/output/",
                                 min_length,
                                 max_length,
                                 accept_language,
                                 true,
                                 true,
                                 0.3,
                                 15000,
                                 &generate_dedup_lsh,
                                 &deduplicator);
    Document document;
    document.text = "Êù±‰∫¨„ÅØ„ÉÉÊô¥„Çå";
    corpus_cleaner.PerplexityFilter(document);
    ASSERT_TRUE(document.perplexity<=15000);
    ASSERT_TRUE(document.is_rejected==false);
    ASSERT_TRUE(document.metadata.find("PerplexityFilter")==document.metadata.end());

    document.text = "Êù±‰∫¨„ÅØÂÖÉÊ∞ó„Åß„Åô";
    corpus_cleaner.PerplexityFilter(document);
    ASSERT_TRUE(document.perplexity<=15000);
    ASSERT_TRUE(document.is_rejected==false);

    document.text = "ÂêæËº©„ÅØÁå´„Åß„ÅÇ„Çã„ÄÇÂêçÂâç„ÅØ„Åæ„Å†„Å™„ÅÑ„ÄÇ";
    corpus_cleaner.PerplexityFilter(document);
    ASSERT_TRUE(document.perplexity<=15000);
    ASSERT_TRUE(document.is_rejected==false);

    document.text = "Êù±‰∫¨„ÅØÊô¥„Çå";
    corpus_cleaner.PerplexityFilter(document);
    ASSERT_TRUE(document.perplexity<=15000);
    ASSERT_TRUE(document.is_rejected==false);

    document.text = "Êù±‰∫¨ Â§ßÈò™ ÂêçÂè§Â±ã ÁßãÁî∞ ÂçÉËëâ";
    document.is_rejected=false;
    corpus_cleaner.PerplexityFilter(document);
    ASSERT_TRUE(document.perplexity>15000);
    ASSERT_TRUE(document.is_rejected==true);
    ASSERT_TRUE(document.metadata.find("PerplexityFilter")!=document.metadata.end());

    document.text = "„ÅÇ„ÅÇ„ÅÇ„ÅÇ„ÅÇ„ÅÇ„ÅÇ";
    document.is_rejected=false;
    corpus_cleaner.PerplexityFilter(document);
    ASSERT_TRUE(document.perplexity<15000);
    ASSERT_TRUE(document.is_rejected==false);

    document.text = "assdofiuslk„ÅÇÔΩìÔΩãÔΩÑÔΩàÔΩäÔΩã";
    document.is_rejected=false;
    corpus_cleaner.PerplexityFilter(document);
    ASSERT_TRUE(document.perplexity<15000);
    ASSERT_TRUE(document.is_rejected==false);


}

TEST_F(CorpusCleanerTest,GetFileNameListWithoutExtention) 
{
    string input_path = "../data/input/sentence_deduplicate";
    vector<string> file_name_list;
    GetFileNameListWithoutExtention(input_path, &file_name_list);
    // cout << file_name_list[0] << endl;
    ASSERT_TRUE(file_name_list[0]=="test_SentenceDeduplication2");
    // cout << file_name_list[1] << endl;
    ASSERT_TRUE(file_name_list[1]=="test_SentenceDeduplication3");
    // cout << file_name_list[2] << endl;
    ASSERT_TRUE(file_name_list[2]=="test_SentenceDeduplication");
}


TEST_F(CorpusCleanerTest,ConvertTextToDocument) 
{
    Document document;
    string sentence = "„Åì„Çì„Å´„Å°„ÅØ„ÄÇÁßÅ„ÅØcelery„Åß„Åô„ÄÇ";
    string filename = "input";
    string file_line_count = "0";
    ConvertTextToDocument(sentence,filename,file_line_count,document);
    ASSERT_TRUE(document.text==sentence);
    ASSERT_TRUE(document.id=="input_0");
    ASSERT_TRUE(document.is_rejected==false);
    ASSERT_TRUE(document.language=="");
    ASSERT_TRUE(document.language_score==-1);
    ASSERT_TRUE(document.perplexity==-1);
}

TEST_F(CorpusCleanerTest,WriteDocumentToJsonl) 
{
    Document document;
    string sentence = "„Åì„Çì„Å´„Å°„ÅØ„ÄÇÁßÅ„ÅØcelery„Åß„Åô„ÄÇ";
    string filename = "input";
    string file_line_count = "0";
    ConvertTextToDocument(sentence,filename,file_line_count,document);
    if (fs::exists("../data/output/write_document_to_jsonl.jsonl")) {
        fs::remove("../data/output/write_document_to_jsonl.jsonl");
    }

    GenerateDedupLSH generate_dedup_lsh(5,200,20,10);
    LSHDeduplicator deduplicator(true,"../data/output/blacklist.txt",true,5120);
    CorpusCleaner corpus_cleaner("../data/input/",
                                 "../data/output/",
                                 min_length,
                                 max_length,
                                 accept_language,
                                 true,
                                 true,
                                 0.3,
                                 15000,
                                 &generate_dedup_lsh,
                                 &deduplicator);
    WriteDocumentToJsonl(document,"../data/output/write_document_to_jsonl.jsonl");
    
    document.text = "„ÅÑ„ÅÑ„Åã„ÅÑ! „ÇÇ„Å£„Å®„ÇÇ„Äé„ÇÄ„Åö„Åã„Åó„ÅÑ‰∫ã„Äè„ÅØ! „ÄéËá™ÂàÜ„Çí‰πó„ÇäË∂ä„Åà„Çã‰∫ã„Äè„Åï!";
    document.id  = "rohan_0"; 
    document.is_rejected = true;
    // document.metadata;
    document.language="__label__ja";
    document.language_score=0.003;
    document.perplexity=1.692;
    WriteDocumentToJsonl(document,"../data/output/write_document_to_jsonl.jsonl");
    
    ifstream input("../data/output/write_document_to_jsonl.jsonl");
    string line;
    getline(input,line);
    // cout << "{\"text\":\"„Åì„Çì„Å´„Å°„ÅØ„ÄÇÁßÅ„ÅØcelery„Åß„Åô„ÄÇ\",\"id\":\"input_0\",\"is_rejected\":\"0\",\"metadata\":\"\",\"language\":\"\",\"language_score\":\"-1\",\"perplexity\":\"-1\"}" << endl;
    // cout << line << endl;
    ASSERT_TRUE(line==string("{\"text\":\"„Åì„Çì„Å´„Å°„ÅØ„ÄÇÁßÅ„ÅØcelery„Åß„Åô„ÄÇ\",\"id\":\"input_0\",\"is_rejected\":\"0\",\"metadata\":\"\",\"language\":\"\",\"language_score\":\"-1\",\"perplexity\":\"-1\"}")); 
    getline(input,line);
    ASSERT_TRUE(line=="{\"text\":\"„ÅÑ„ÅÑ„Åã„ÅÑ! „ÇÇ„Å£„Å®„ÇÇ„Äé„ÇÄ„Åö„Åã„Åó„ÅÑ‰∫ã„Äè„ÅØ! „ÄéËá™ÂàÜ„Çí‰πó„ÇäË∂ä„Åà„Çã‰∫ã„Äè„Åï!\",\"id\":\"rohan_0\",\"is_rejected\":\"1\",\"metadata\":\"\",\"language\":\"__label__ja\",\"language_score\":\"0.003\",\"perplexity\":\"1.692\"}" );    
    input.close();
}

TEST_F(CorpusCleanerTest,ReadDocumentFromJsonlOneLine) 
{
    GenerateDedupLSH generate_dedup_lsh(5,200,20,10);
    LSHDeduplicator deduplicator(true,"../data/output/blacklist.txt",true,5120);
    CorpusCleaner corpus_cleaner("../data/input/",
                                 "../data/output/",
                                 min_length,
                                 max_length,
                                 accept_language,
                                 true,
                                 true,
                                 0.3,
                                 15000,
                                 &generate_dedup_lsh,
                                 &deduplicator);
    Document document;
    string jsonl_line = "{\"text\":\"„ÄéË¶öÊÇü„Äè„Å®„ÅØ!! ÊöóÈóá„ÅÆËçíÈáé„Å´!! ÈÄ≤„ÇÄ„Åπ„ÅçÈÅì„ÇíÂàá„ÇäÈñã„Åè‰∫ã„Å†„ÉÉ!\",\"id\":\"jorno_0\",\"is_rejected\":\"1\",\"metadata\":\"\",\"language\":\"__label__ja\",\"language_score\":\"0.003\",\"perplexity\":\"1.692\"}";
    
    ReadDocumentFromJsonlOneLine(document,jsonl_line);
    ASSERT_TRUE(document.text=="„ÄéË¶öÊÇü„Äè„Å®„ÅØ!! ÊöóÈóá„ÅÆËçíÈáé„Å´!! ÈÄ≤„ÇÄ„Åπ„ÅçÈÅì„ÇíÂàá„ÇäÈñã„Åè‰∫ã„Å†„ÉÉ!");
    ASSERT_TRUE(document.id=="jorno_0");
    ASSERT_TRUE(document.is_rejected==true);
    ASSERT_TRUE(document.language=="__label__ja");
    EXPECT_NEAR(document.language_score,0.003,0.0001);
    EXPECT_NEAR(document.perplexity,1.692,0.0001);    
}

TEST_F(CorpusCleanerTest,ExceptionReadDocumentFromJsonlOneLine)
{
    GenerateDedupLSH generate_dedup_lsh(5,200,20,10);
    LSHDeduplicator deduplicator(true,"../data/output/blacklist.txt",true,5120);
    CorpusCleaner corpus_cleaner("../data/input/",
                                 "../data/output/",
                                 min_length,
                                 max_length,
                                 accept_language,
                                 true,
                                 true,
                                 0.3,
                                 15000,
                                 &generate_dedup_lsh,
                                 &deduplicator);
    Document document;
    // jsonl_line without data
    string jsonl_line = "{}";
    EXPECT_ANY_THROW(ReadDocumentFromJsonlOneLine(document,jsonl_line));
}